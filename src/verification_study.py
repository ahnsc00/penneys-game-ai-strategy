import numpy as np
import random
from collections import defaultdict
import matplotlib.pyplot as plt

class PenneysGameVerification:
    """í˜ë‹ˆì˜ ê²Œì„ ì „ëµ ê²€ì¦ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.sequences = ['HHH', 'HHT', 'HTH', 'HTT', 'THH', 'THT', 'TTH', 'TTT']
        
    def simulate_single_game(self, seq1, seq2):
        """ë‹¨ì¼ ê²Œì„ ì‹œë®¬ë ˆì´ì…˜ (ë” ì •í™•í•œ êµ¬í˜„)"""
        if seq1 == seq2:
            return random.choice([1, 2])
        
        coin_sequence = ""
        max_length = 10000  # ë¬´í•œ ë£¨í”„ ë°©ì§€
        
        for _ in range(max_length):
            coin_sequence += random.choice(['H', 'T'])
            if len(coin_sequence) >= 3:
                recent = coin_sequence[-3:]
                if recent == seq1:
                    return 1
                elif recent == seq2:
                    return 2
                    
                # ë” ê¸´ íŒ¨í„´ë„ ì²´í¬ (ê²¹ì¹˜ëŠ” ê²½ìš°)
                if len(coin_sequence) >= 4:
                    recent_4 = coin_sequence[-4:]
                    if recent_4[-3:] == seq1 and recent_4[:-1] != seq2:
                        return 1
                    elif recent_4[:-1] == seq2 and recent_4[-3:] != seq1:
                        return 2
        
        return random.choice([1, 2])  # ê·¹íˆ ë“œë¬¸ ê²½ìš°

class MultipleTrainingVerification:
    """ì—¬ëŸ¬ ë²ˆì˜ ë…ë¦½ì  RL í›ˆë ¨ì„ í†µí•œ ê²€ì¦"""
    
    def __init__(self):
        self.env = PenneysGameVerification()
        
    def run_independent_training(self, episodes=100000):
        """ë…ë¦½ì ì¸ Q-ëŸ¬ë‹ í›ˆë ¨ ì‹¤í–‰"""
        q_table = defaultdict(lambda: np.zeros(8))
        learning_rate = 0.1
        epsilon = 0.1
        
        for episode in range(episodes):
            # ìƒíƒœ (Player 1ì˜ ì„ íƒ)
            state = random.randint(0, 7)
            player1_seq = self.env.sequences[state]
            
            # í–‰ë™ ì„ íƒ (epsilon-greedy)
            if random.random() < epsilon:
                action = random.randint(0, 7)
            else:
                action = np.argmax(q_table[state])
            
            player2_seq = self.env.sequences[action]
            
            # ê²Œì„ ì‹œë®¬ë ˆì´ì…˜
            winner = self.env.simulate_single_game(player1_seq, player2_seq)
            reward = 1 if winner == 2 else -1
            
            # Q-í…Œì´ë¸” ì—…ë°ì´íŠ¸
            q_table[state][action] += learning_rate * (reward - q_table[state][action])
        
        # ìµœì¢… ì •ì±… ì¶”ì¶œ
        policy = {}
        for state in range(8):
            best_action = np.argmax(q_table[state])
            policy[self.env.sequences[state]] = self.env.sequences[best_action]
        
        return policy
    
    def verify_consistency(self, num_runs=5):
        """ì—¬ëŸ¬ ë²ˆì˜ ë…ë¦½ì  í›ˆë ¨ìœ¼ë¡œ ì¼ê´€ì„± ê²€ì¦"""
        print("ğŸ”¬ ì—¬ëŸ¬ ë²ˆì˜ ë…ë¦½ì  RL í›ˆë ¨ì„ í†µí•œ ê²€ì¦")
        print("=" * 60)
        
        all_policies = []
        
        for run in range(num_runs):
            print(f"í›ˆë ¨ ì‹¤í–‰ {run+1}/{num_runs}...")
            policy = self.run_independent_training()
            all_policies.append(policy)
        
        # ì¼ê´€ì„± ë¶„ì„
        print(f"\nğŸ“Š {num_runs}ë²ˆ ë…ë¦½ í›ˆë ¨ ê²°ê³¼ ë¹„êµ")
        print("-" * 60)
        print("ìƒëŒ€ ë°°ì—´ |", end="")
        for i in range(num_runs):
            print(f" í›ˆë ¨{i+1} |", end="")
        print(" ì¼ê´€ì„±")
        print("-" * 60)
        
        consistency_count = 0
        total_cases = len(self.env.sequences)
        
        for opponent in self.env.sequences:
            responses = [policy[opponent] for policy in all_policies]
            is_consistent = len(set(responses)) == 1
            
            print(f"   {opponent}   |", end="")
            for response in responses:
                print(f"  {response} |", end="")
            
            if is_consistent:
                print(" âœ“ ì¼ê´€ë¨")
                consistency_count += 1
            else:
                print(" âœ— ë¶ˆì¼ì¹˜")
        
        consistency_rate = consistency_count / total_cases * 100
        print("-" * 60)
        print(f"ì „ì²´ ì¼ê´€ì„±: {consistency_count}/{total_cases} = {consistency_rate:.1f}%")
        
        return all_policies, consistency_rate

class TheoreticalProbabilityAnalysis:
    """ì´ë¡ ì  í™•ë¥  ë¶„ì„"""
    
    def __init__(self):
        pass
    
    def calculate_exact_probability(self, seq1, seq2, num_simulations=1000000):
        """ì •í™•í•œ í™•ë¥  ê³„ì‚° (ëŒ€ê·œëª¨ ì‹œë®¬ë ˆì´ì…˜)"""
        if seq1 == seq2:
            return 0.5
        
        wins = 0
        env = PenneysGameVerification()
        
        for _ in range(num_simulations):
            winner = env.simulate_single_game(seq1, seq2)
            if winner == 2:  # seq2 ìŠ¹ë¦¬
                wins += 1
        
        return wins / num_simulations
    
    def analyze_disputed_cases(self):
        """ë…¼ë€ì´ ìˆëŠ” ì¼€ì´ìŠ¤ë“¤ì— ëŒ€í•œ ì •ë°€ ë¶„ì„"""
        print("\nğŸ¯ ë…¼ë€ ì¼€ì´ìŠ¤ ì •ë°€ í™•ë¥  ë¶„ì„")
        print("=" * 50)
        
        # ë…¼ë€ì´ ìˆëŠ” ì¼€ì´ìŠ¤ë“¤
        disputed_cases = [
            ('HHH', 'TTT'),  # AI ì„ íƒ
            ('HHH', 'THH'),  # ì½˜ì›¨ì´ ì„ íƒ
            ('HTH', 'TTH'),  # AI ì„ íƒ  
            ('HTH', 'HHT'),  # ì½˜ì›¨ì´ ì„ íƒ
        ]
        
        results = {}
        
        for seq1, seq2 in disputed_cases:
            print(f"\në¶„ì„ ì¤‘: {seq1} vs {seq2}...")
            prob = self.calculate_exact_probability(seq1, seq2)
            results[(seq1, seq2)] = prob
            print(f"{seq1} vs {seq2}: {seq2} ìŠ¹ë¥  = {prob:.4f} ({prob*100:.2f}%)")
        
        print(f"\nğŸ” HHH ì¼€ì´ìŠ¤ ë¹„êµ:")
        ttt_prob = results[('HHH', 'TTT')]
        thh_prob = results[('HHH', 'THH')]
        print(f"  HHH vs TTT (AI): TTT ìŠ¹ë¥  = {ttt_prob:.4f} ({ttt_prob*100:.2f}%)")
        print(f"  HHH vs THH (ì½˜ì›¨ì´): THH ìŠ¹ë¥  = {thh_prob:.4f} ({thh_prob*100:.2f}%)")
        
        if thh_prob > ttt_prob:
            print(f"  ğŸ† ê²°ë¡ : ì½˜ì›¨ì´ê°€ {(thh_prob-ttt_prob)*100:.2f}%p ë” ìš°ìˆ˜!")
        else:
            print(f"  ğŸ† ê²°ë¡ : AIê°€ {(ttt_prob-thh_prob)*100:.2f}%p ë” ìš°ìˆ˜!")
        
        print(f"\nğŸ” HTH ì¼€ì´ìŠ¤ ë¹„êµ:")
        tth_prob = results[('HTH', 'TTH')]
        hht_prob = results[('HTH', 'HHT')]
        print(f"  HTH vs TTH (AI): TTH ìŠ¹ë¥  = {tth_prob:.4f} ({tth_prob*100:.2f}%)")
        print(f"  HTH vs HHT (ì½˜ì›¨ì´): HHT ìŠ¹ë¥  = {hht_prob:.4f} ({hht_prob*100:.2f}%)")
        
        if tth_prob > hht_prob:
            print(f"  ğŸ† ê²°ë¡ : AIê°€ {(tth_prob-hht_prob)*100:.2f}%p ë” ìš°ìˆ˜!")
        else:
            print(f"  ğŸ† ê²°ë¡ : ì½˜ì›¨ì´ê°€ {(hht_prob-tth_prob)*100:.2f}%p ë” ìš°ìˆ˜!")
        
        return results

class HeadToHeadTournament:
    """AI ì „ëµ vs ì½˜ì›¨ì´ ì „ëµ ì§ì ‘ ëŒ€ê²°"""
    
    def __init__(self):
        self.env = PenneysGameVerification()
        
        # AI ë°œê²¬ ì „ëµ
        self.ai_strategy = {
            'HHH': 'TTT', 'HHT': 'THH', 'HTH': 'TTH', 'HTT': 'HHT',
            'THH': 'TTH', 'THT': 'TTH', 'TTH': 'HTT', 'TTT': 'HTT'
        }
        
        # ìˆœìˆ˜ ì½˜ì›¨ì´ ì „ëµ
        self.conway_strategy = {}
        for opponent in self.env.sequences:
            flip = lambda x: 'T' if x == 'H' else 'H'
            o1, o2, o3 = opponent[0], opponent[1], opponent[2]
            self.conway_strategy[opponent] = flip(o2) + o1 + o2
    
    def tournament(self, games_per_case=100000):
        """ì „ë©´ì  í† ë„ˆë¨¼íŠ¸"""
        print("\nâš”ï¸  AI ì „ëµ vs ì½˜ì›¨ì´ ì „ëµ ì§ì ‘ ëŒ€ê²°")
        print("=" * 60)
        
        ai_total_wins = 0
        conway_total_wins = 0
        total_games = 0
        
        print("ìƒëŒ€ ì„ íƒ | AI ì‘ë‹µ | ì½˜ì›¨ì´ ì‘ë‹µ | AI ìŠ¹ë¥  | ì½˜ì›¨ì´ ìŠ¹ë¥  | ìŠ¹ì")
        print("-" * 70)
        
        for opponent in self.env.sequences:
            ai_response = self.ai_strategy[opponent]
            conway_response = self.conway_strategy[opponent]
            
            # AI ì „ëµ í…ŒìŠ¤íŠ¸
            ai_wins = 0
            for _ in range(games_per_case):
                winner = self.env.simulate_single_game(opponent, ai_response)
                if winner == 2:
                    ai_wins += 1
            
            # ì½˜ì›¨ì´ ì „ëµ í…ŒìŠ¤íŠ¸  
            conway_wins = 0
            for _ in range(games_per_case):
                winner = self.env.simulate_single_game(opponent, conway_response)
                if winner == 2:
                    conway_wins += 1
            
            ai_winrate = ai_wins / games_per_case
            conway_winrate = conway_wins / games_per_case
            
            ai_total_wins += ai_wins
            conway_total_wins += conway_wins
            total_games += games_per_case * 2
            
            # ìŠ¹ì ê²°ì •
            if ai_winrate > conway_winrate:
                winner_mark = "ğŸ”¥ AI"
            elif conway_winrate > ai_winrate:
                winner_mark = "â­ ì½˜ì›¨ì´"
            else:
                winner_mark = "ğŸ¤ ë™ì "
            
            print(f"   {opponent}   |  {ai_response}  |   {conway_response}   | {ai_winrate:.3f} | {conway_winrate:.3f} | {winner_mark}")
        
        # ì „ì²´ ê²°ê³¼
        overall_ai = ai_total_wins / (games_per_case * len(self.env.sequences))
        overall_conway = conway_total_wins / (games_per_case * len(self.env.sequences))
        
        print("-" * 70)
        print(f"ì „ì²´ í‰ê·  | {'':7} | {'':9} | {overall_ai:.3f} | {overall_conway:.3f} |", end="")
        
        if overall_ai > overall_conway:
            print(" ğŸ† AI ìŠ¹ë¦¬!")
        elif overall_conway > overall_ai:
            print(" ğŸ† ì½˜ì›¨ì´ ìŠ¹ë¦¬!")
        else:
            print(" ğŸ¤ ë™ì !")
        
        return overall_ai, overall_conway

def main():
    """ë©”ì¸ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸ”¬ í˜ë‹ˆì˜ ê²Œì„ AI ì „ëµ ì² ì € ê²€ì¦")
    print("=" * 80)
    
    # 1ë‹¨ê³„: ì—¬ëŸ¬ ë²ˆì˜ ë…ë¦½ì  í›ˆë ¨ìœ¼ë¡œ ì¼ê´€ì„± ê²€ì¦
    verification = MultipleTrainingVerification()
    policies, consistency = verification.verify_consistency(num_runs=3)
    
    # 2ë‹¨ê³„: ì´ë¡ ì  í™•ë¥  ë¶„ì„
    theory_analysis = TheoreticalProbabilityAnalysis()
    probability_results = theory_analysis.analyze_disputed_cases()
    
    # 3ë‹¨ê³„: ì§ì ‘ ëŒ€ê²° í† ë„ˆë¨¼íŠ¸
    tournament = HeadToHeadTournament()
    ai_performance, conway_performance = tournament.tournament()
    
    # ìµœì¢… ê²°ë¡ 
    print(f"\n" + "ğŸ¯" * 30)
    print("ğŸ”¬ ìµœì¢… ê²€ì¦ ê²°ê³¼")
    print("ğŸ¯" * 30)
    
    print(f"1ï¸âƒ£  RL í›ˆë ¨ ì¼ê´€ì„±: {consistency:.1f}%")
    if consistency >= 80:
        print("   âœ… ë†’ì€ ì¼ê´€ì„± - AI ë°œê²¬ì´ ìš°ì—°ì´ ì•„ë‹˜ì„ ì‹œì‚¬")
    else:
        print("   âš ï¸  ë‚®ì€ ì¼ê´€ì„± - ì¶”ê°€ ê²€í†  í•„ìš”")
    
    print(f"2ï¸âƒ£  ì´ë¡ ì  í™•ë¥  ë¶„ì„: ì™„ë£Œ")
    print("   ğŸ“Š ì •ë°€í•œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì‹¤ì œ ìŠ¹ë¥  ì¸¡ì •")
    
    print(f"3ï¸âƒ£  ì§ì ‘ ëŒ€ê²° ê²°ê³¼:")
    print(f"   ğŸ¤– AI ì „ëµ í‰ê·  ìŠ¹ë¥ : {ai_performance:.3f}")
    print(f"   ğŸ“š ì½˜ì›¨ì´ ì „ëµ í‰ê·  ìŠ¹ë¥ : {conway_performance:.3f}")
    
    if ai_performance > conway_performance:
        print("   ğŸ† ê²°ë¡ : AI ì „ëµì´ ì‹¤ì œë¡œ ë” ìš°ìˆ˜í•¨!")
    else:
        print("   ğŸ† ê²°ë¡ : ì½˜ì›¨ì´ ì „ëµì´ ë” ìš°ìˆ˜í•¨!")

if __name__ == "__main__":
    main()